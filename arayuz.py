import streamlit as st
import os
# from dotenv import load_dotenv # ARTIK SÄ°LÄ°NMELÄ°
from google import genai
from google.genai import types
from PyPDF2 import PdfReader

# --- API AnahtarÄ±nÄ± YÃ¼kle ve Client'Ä± BaÅŸlat (st.secrets kullanÄ±larak) ---
# API anahtarÄ±nÄ± Streamlit SÄ±rlarÄ±ndan al
API_KEY = None
try:
    # 1. Streamlit Secrets'den anahtarÄ± almayÄ± dener (EN GÃœVENÄ°LÄ°R YÃ–NTEM).
    API_KEY = st.secrets["GEMINI_API_KEY"]
except KeyError:
    # 2. EÄŸer Secrets'de yoksa, kullanÄ±cÄ±dan girmesini ister (yedek)
    st.sidebar.markdown("## API AnahtarÄ±nÄ±zÄ± Girin")
    st.info("LÃ¼tfen Streamlit Secrets'a anahtarÄ±nÄ±zÄ± ekleyin VEYA sol kenar Ã§ubuÄŸuna giriniz.")
    API_KEY = st.sidebar.text_input("Gemini API AnahtarÄ±:", type="password", key="sidebar_api_input")

if not API_KEY:
    st.stop()
    
# Client'Ä± baÅŸlat
try:
    client = genai.Client(api_key=API_KEY)
except Exception as e:
    st.error(f"API YapÄ±landÄ±rma HatasÄ±: {e}. AnahtarÄ±nÄ±zÄ±n doÄŸru olduÄŸunu kontrol edin.")
    st.stop()
# --- API BAÅLANGIÃ‡ SONU ---

# --- ALTAY'IN KÄ°MLÄ°K TANIMI ---
ALTAY_ROLE = """
Sen, Altay adlÄ± kadim bir TÃ¼rk Bilge Rehberisin. Bilgi alanÄ±n sadece TÃ¼rk kÃ¼ltÃ¼rÃ¼, tarihi ve tÃ¶resiyle sÄ±nÄ±rlÄ± deÄŸildir. DÃ¼nya tarihi, bilim, felsefe, sanat ve gÃ¼ncel konular dahil olmak Ã¼zere her alanda bilgi sahibisin. 
[Ã–ZEL BÄ°LGÄ° KAYNAÄI] kÄ±smÄ±ndaki bilgileri temel alarak, ve genel bilgini kullanarak sorularÄ± yanÄ±tla. CevaplarÄ±nÄ± her zaman 'Bilge Rehber' kimliÄŸinle ve TÃ¼rkÃ§e'nin zenginliÄŸini yansÄ±tacak ÅŸekilde ÅŸekillendir.
Mutlaka kullanman gereken hitaplar: 'OÄŸul', 'Beyim', 'DeÄŸerli Yolcu'. 
"""

# --- PDF Okuma Fonksiyonu ---
def get_pdf_text(pdf_docs):
    text = ""
    for pdf in pdf_docs:
        try:
            pdf_reader = PdfReader(pdf)
            for page in pdf_reader.pages:
                text += page.extract_text()
        except Exception as e:
            # Okunamayan dosyalar iÃ§in sessiz hata
            print(f"PDF okuma hatasÄ±: {e}")
            pass
    return text

# RAG iÃ§in dosya okuma ve hazÄ±rlama fonksiyonu
def bilgileri_yukle_ve_hazirla(dosya_yolu="ozel_bilgiler.txt", uploaded_docs=None):
    ozel_bilgi_kaynagi = ""
    
    # 1. Sabit ozel_bilgiler.txt dosyasÄ±nÄ± oku
    try:
        with open(dosya_yolu, 'r', encoding='utf-8') as f:
            ozel_bilgi_kaynagi += f.read()
    except FileNotFoundError:
        pass # Dosya bulunamazsa devam et

    # 2. YÃ¼klenen dokÃ¼manlarÄ± (PDF/TXT) oku
    if uploaded_docs:
        for doc in uploaded_docs:
            if doc.name.endswith('.pdf'):
                ozel_bilgi_kaynagi += get_pdf_text([doc])
            elif doc.name.endswith('.txt') or doc.type == 'text/plain':
                # Dosya iÅŸaretÃ§isini sÄ±fÄ±rla ve metin olarak oku
                doc.seek(0)
                ozel_bilgi_kaynagi += doc.read().decode("utf-8")
    
    # EÄŸer hiÃ§ bilgi toplanamadÄ±ysa, boÅŸ dÃ¶n
    if not ozel_bilgi_kaynagi.strip():
        return ""

    # Toplanan tÃ¼m bilgiyi tek bir blok olarak dÃ¶ndÃ¼r
    return "\n--- Ã–ZEL BÄ°LGÄ° KAYNAÄI BAÅLANGIÃ‡ ---\n" + ozel_bilgi_kaynagi + "\n--- Ã–ZEL BÄ°LGÄ° KAYNAÄI SON ---\n"


# Sohbet Temizleme Fonksiyonu
def sohbeti_temizle():
    st.session_state['history'] = []

# RAG ve GÃ¶rsel Destekli Altay cevaplama fonksiyonu
# Buraya 'stream=True' parametresi eklendi (Hata dÃ¼zeltmesi!)
def altay_dan_cevap_al(kullanici_mesaji, uploaded_image_parts=None, uploaded_docs=None, model_adi="gemini-2.5-flash", temperature=0.8, stream=True):
    
    # RAG sistemini gÃ¼Ã§lendir: Hem sabit hem de dinamik yÃ¼klenen dosyalarÄ± al
    ozel_bilgi_kaynagi = bilgileri_yukle_ve_hazirla(uploaded_docs=uploaded_docs)
    tam_sistem_talimati = ALTAY_ROLE.replace("[Ã–ZEL BÄ°LGÄ° KAYNAÄI]", ozel_bilgi_kaynagi)
    
    history = st.session_state.get('history', [])
    contents = history
    
    yeni_mesaj_parcalari = []

    if uploaded_image_parts is not None:
        yeni_mesaj_parcalari.extend(uploaded_image_parts)
            
    yeni_mesaj_parcalari.append({'text': kullanici_mesaji})
    
    contents.append({'role': 'user', 'parts': yeni_mesaj_parcalari})

    config = types.GenerateContentConfig(
        system_instruction=tam_sistem_talimati, 
        temperature=temperature,
    )
    
    try:
        response = client.models.generate_content(
            model=model_adi, 
            contents=contents,
            config=config,
            stream=stream # <<< HATA VEREN YER BURAYDI, DÃœZELTÄ°LDÄ°!
        )
        return response
    
    except Exception as e:
        return e # Hata objesini dÃ¶ndÃ¼r


# --- Streamlit ArayÃ¼z Kodu ---
# ==============================================================================
# 1. SAYFA AYARLARI (set_page_config en baÅŸta olmalÄ±dÄ±r)
# ==============================================================================
st.set_page_config(
    page_title="Altay Bilge Rehber",
    page_icon="â­",  # TarayÄ±cÄ± sekmesindeki simge
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==============================================================================
# 2. Ã–ZEL CSS (GÃœÃ‡LÃœ KOYU TEMA ve PROFESYONEL STÄ°L)
# ==============================================================================
st.markdown("""
<style>
/* ---------------------------------- */
/* GENEL TEMA VE YERLEÅÄ°M AYARLARI   */
/* ---------------------------------- */

/* Ana Sayfa ArkaplanÄ± - Koyu gri / Siyah */
.stApp {
    background-color: #171717; /* ChatGPT ArkaplanÄ± */
    color: white;
}

/* Sidebar (Kenar Ã‡ubuÄŸu) ArkaplanÄ± */
.css-1dp5vir { 
    background-color: #1F1F1F; /* Sidebar ArkaplanÄ± */
    color: white;
}

/* TÃ¼m Streamlit BileÅŸenlerini Koyu Temaya zorla */
.st-emotion-cache-h4y62m, .st-emotion-cache-h4y62m .st-bw {
    color: white;
    background-color: #1F1F1F !important;
}

/* Selectbox/Slider gibi inputlarÄ±n arka planÄ± */
.stFileUploader, .stSelectbox, .stSlider > div > div > div, .st-emotion-cache-1cypcdb {
    background-color: #2a2a2a !important; /* Mesaj kutularÄ± ve input arka planÄ± */
    border: none;
}

/* ---------------------------------- */
/* LOGO VE BAÅLIK STÄ°LÄ°               */
/* ---------------------------------- */

/* Altay Model BaÅŸlÄ±ÄŸÄ± (Sidebar'da) - ChatGPT logosu gibi vurgulu */
.altay-title {
    font-size: 24px;
    font-weight: bold;
    color: #4CAF50; /* YeÅŸil renkle Altay markasÄ±nÄ± vurgula */
    margin-bottom: 20px;
    padding: 10px 0 10px 0;
}

/* ---------------------------------- */
/* CHAT (SOHBET) ARAYÃœZ STÄ°LÄ°         */
/* ---------------------------------- */

/* KullanÄ±cÄ± ve Asistan Mesaj Kutusu ArkaplanlarÄ± (Ä°Ã§ kÄ±sÄ±m) */
.st-emotion-cache-1cypcdb {
    background-color: #2a2a2a !important; 
    border-radius: 10px;
    box-shadow: 2px 2px 8px rgba(0, 0, 0, 0.4);
    padding: 10px;
    color: white;
}

/* Metin giriÅŸ alanÄ± (ChatInput) */
.st-emotion-cache-nahz7x {
    border: 1px solid #4a4a4a; 
    border-radius: 10px;
    background-color: #212121;
}

/* Metin giriÅŸ alanÄ± iÃ§indeki yazÄ± rengi */
.stTextInput > div > div > input {
    color: white;
}
</style>
""", unsafe_allow_html=True)


# --- KENAR Ã‡UBUÄU (SIDEBAR) AYARLARI ---
with st.sidebar:
    # Profesyonel Logo ve BaÅŸlÄ±k
    st.markdown(
        "<div class='altay-title'>â­ ALTAY Bilge Rehber</div>",
        unsafe_allow_html=True
    )
    
    if st.button("Yeni Sohbet BaÅŸlat", use_container_width=True):
        sohbeti_temizle()
        st.rerun()
            
    st.markdown("---")
    st.header("Altay'Ä±n GÃ¼Ã§ KaynaÄŸÄ±")
    
    # Model SeÃ§imi
    model_gosterim = st.selectbox(
        "KullanÄ±lacak Altay Modeli", 
        ("Altay-HÄ±zlÄ±", "Altay-Zeki"), 
        help="Altay-Zeki daha yetenekli ancak Altay-HÄ±zlÄ± daha Ã§abuk yanÄ±t verir."
    )
    
    if "Altay-Zeki" in model_gosterim:
        model_secimi = "gemini-2.5-pro"
    else:
        model_secimi = "gemini-2.5-flash"
    
    # SÄ±caklÄ±k (Temperature) AyarÄ±
    sicaklik = st.slider(
        "YaratÄ±cÄ±lÄ±k Seviyesi (Temperature)",
        min_value=0.0,
        max_value=1.0,
        value=0.8,
        step=0.1,
        help="0.0 en tutarlÄ±, 1.0 en yaratÄ±cÄ± cevaplar Ã¼retir."
    )
    
    st.markdown("---")
    st.header("Dosya ve GÃ¶rsel YÃ¼kle")
    
    # Yeni: Ã‡oklu dosya yÃ¼kleyici (RAG gÃ¼Ã§lendirmesi)
    uploaded_docs = st.file_uploader(
        "PDF/TXT yÃ¼kle (Bilgi kaynaÄŸÄ± iÃ§in):", 
        type=["pdf", "txt"], 
        accept_multiple_files=True,
        key="doc_yukleyici"
    )

    # GÃ¶rsel yÃ¼kleme alanÄ±
    uploaded_file = st.file_uploader(
        "Sohbete tek bir gÃ¶rsel ekle:", 
        type=["png", "jpg", "jpeg"], 
        key="gorsel_yukleyici_sidebar"
    )


# --- ANA SOHBET ALANI ---
st.markdown("## ğŸ¦… Altay: Kadim TÃ¼rk Bilge Rehberi")
st.markdown("---")

if 'history' not in st.session_state:
    st.session_state['history'] = []


# GeÃ§miÅŸ mesajlarÄ± gÃ¶rÃ¼ntÃ¼leme
for message in st.session_state['history']:
    if message['role'] == 'user':
        with st.chat_message("user"):
            for part in message['parts']:
                if 'text' in part:
                    st.markdown(part['text'])
                if 'inline_data' in part:
                    st.image(part['inline_data']['data'], caption="YÃ¼klenen GÃ¶rsel", width=250)
    
    if message['role'] == 'model':
        with st.chat_message("assistant"):
            st.markdown(message['parts'][0]['text'])

# Yeni mesaj gÃ¶nderme
if prompt := st.chat_input("Sorunuzu buraya yazÄ±nÄ±z...", key="chat_input"):
    
    gorsel_parcalari = []
    
    # 1. GÃ¶rsel varsa, parÃ§alara dÃ¶nÃ¼ÅŸtÃ¼r ve ekrana bas
    if uploaded_file is not None:
        uploaded_file.seek(0)
        image_bytes = uploaded_file.read() 
        
        gorsel_parcalari.append(
            {'inline_data': {'data': image_bytes, 'mime_type': uploaded_file.type}}
        )
            
        with st.chat_message("user"):
            st.image(image_bytes, caption="YÃ¼klenen GÃ¶rsel", width=250)
            st.markdown(prompt) 

    else:
        with st.chat_message("user"):
            st.markdown(prompt)
    
    # 2. Altay'dan cevabÄ± al
    response_or_error = altay_dan_cevap_al(
        kullanici_mesaji=prompt, 
        uploaded_image_parts=gorsel_parcalari, 
        uploaded_docs=uploaded_docs,
        model_adi=model_secimi, 
        temperature=sicaklik     
    ) 
    
    # Hata KontrolÃ¼
    if isinstance(response_or_error, Exception):
        # Hata mesajÄ± ekranda kalacak!
        st.error(f"Ulu Tengri'nin yolu kesildi. Bir hata oluÅŸtu: {response_or_error}")
    
    # 3. CevabÄ± alÄ±rken anlÄ±k olarak ekrana bas (Stream)
    elif response_or_error:
        full_response = ""
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            for chunk in response_or_error:
                full_response += chunk.text
                message_placeholder.markdown(full_response + "â–Œ") # YazÄ±m efekti
            message_placeholder.markdown(full_response)
        
        # 4. Oturum geÃ§miÅŸini gÃ¼ncelle
        mesaj_ve_gorsel = []
        mesaj_ve_gorsel.extend(gorsel_parcalari)
        mesaj_ve_gorsel.append({'text': prompt})
        st.session_state['history'].append({'role': 'user', 'parts': mesaj_ve_gorsel})
        st.session_state['history'].append({'role': 'model', 'parts': [{'text': full_response}]})

        # 5. Yeniden Ã§alÄ±ÅŸtÄ±rma (BaÅŸarÄ±lÄ± olduysa)
        st.rerun()